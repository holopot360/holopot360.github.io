<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>WebGL + Fast Camera Brightness Detection</title>
  <style>
    html, body {
      margin: 0; padding: 0; height: 100%; background: black; overflow: hidden;
    }
    #glCanvas {
      display: block;
      position: absolute;
      left: 50%;
      transform: translateX(-50%);
    }
    /* Hidden video & canvas for brightness detection */
    #video, #camCanvas { display: none; }
  </style>
</head>
<body>

<!-- WebGL Canvas -->
<canvas id="glCanvas"></canvas>

<!-- Hidden camera elements (just used for brightness detection) -->
<video id="video" playsinline></video>
<canvas id="camCanvas" width="32" height="32"></canvas>

<script>
(function() {
  // ---------------------------------------------------------
  // 1) Parse URL params: mode, frequency, rps, numViews
  // ---------------------------------------------------------
  const params = new URLSearchParams(window.location.search);
  const mode      = params.get('mode') || 'test'; // "test", "viking4", "viking32", "statue32"
  const freq      = parseFloat(params.get('frequency') || '120');
  const rps       = parseFloat(params.get('rps') || '3.75');
  const numViews  = parseFloat(params.get('numViews') || '32');
  const skipSprite = 32 / numViews;

  // framesToSwitch => how many frames pass before toggling/moving
  let framesToSwitch;
  if (mode === 'test') {
    // same as before
    framesToSwitch = (freq / rps) * 0.5; 
  } else if (mode === 'viking32' || mode === 'statue32') {
    // use the new formula: (freq / rps) * (1 / numViews)
    framesToSwitch = (freq / rps) * (1 / numViews);
  } else {
    // default for other texture modes (e.g. "viking4")
    framesToSwitch = (freq / rps) * 0.25;
  }

  framesToSwitch = Math.round(framesToSwitch);
  if (framesToSwitch < 1) framesToSwitch = 1;

  // ---------------------------------------------------------
  // 2) Canvas and WebGL setup
  // ---------------------------------------------------------
  const canvas = document.getElementById('glCanvas');
  const gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');
  if (!gl) {
    alert('WebGL not supported');
    return;
  }

  function resizeCanvas() {
    const h = window.innerHeight;
    const w = h / 2; // half the height => tall vertical layout

    canvas.style.height = h + 'px';
    canvas.style.width  = w + 'px';

    canvas.width  = w;
    canvas.height = h;
    gl.viewport(0, 0, gl.drawingBufferWidth, gl.drawingBufferHeight);
  }
  window.addEventListener('resize', resizeCanvas);
  resizeCanvas();

  // Toggle fullscreen on click
  canvas.addEventListener('click', () => {
    if (!document.fullscreenElement) {
      canvas.requestFullscreen();
    } else {
      document.exitFullscreen();
    }
  });

  // ---------------------------------------------------------
  // 3) Shaders
  // ---------------------------------------------------------
  const vsSource = `
    attribute vec2 aPosition;
    attribute vec2 aTexCoord;
    attribute float aColorMode;

    varying vec2  vTexCoord;
    varying float vColorMode;

    void main(void) {
      vTexCoord  = aTexCoord;
      vColorMode = aColorMode;
      gl_Position = vec4(aPosition, 0.0, 1.0);
    }
  `;

  const fsSource = `
    precision mediump float;

    varying vec2  vTexCoord;
    varying float vColorMode;

    uniform vec4  uSolidColor;
    uniform sampler2D uSampler;

    void main(void) {
      // If vColorMode > 0.5 => "test" mode => solid color
      // else => "texture" mode => sample from sprite
      if (vColorMode > 0.5) {
        gl_FragColor = uSolidColor;
      } else {
        gl_FragColor = texture2D(uSampler, vTexCoord);
      }
    }
  `;

  function loadShader(type, source) {
    const shader = gl.createShader(type);
    gl.shaderSource(shader, source);
    gl.compileShader(shader);
    if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
      console.error('Error compiling shader:', gl.getShaderInfoLog(shader));
      gl.deleteShader(shader);
      return null;
    }
    return shader;
  }

  const vertexShader   = loadShader(gl.VERTEX_SHADER, vsSource);
  const fragmentShader = loadShader(gl.FRAGMENT_SHADER, fsSource);

  const shaderProgram = gl.createProgram();
  gl.attachShader(shaderProgram, vertexShader);
  gl.attachShader(shaderProgram, fragmentShader);
  gl.linkProgram(shaderProgram);

  if (!gl.getProgramParameter(shaderProgram, gl.LINK_STATUS)) {
    console.error('Could not link shader program:', gl.getProgramInfoLog(shaderProgram));
    return;
  }

  gl.useProgram(shaderProgram);

  // Location lookups
  const aPosition   = gl.getAttribLocation(shaderProgram, 'aPosition');
  const aTexCoord   = gl.getAttribLocation(shaderProgram, 'aTexCoord');
  const aColorMode  = gl.getAttribLocation(shaderProgram, 'aColorMode');
  const uSolidColor = gl.getUniformLocation(shaderProgram, 'uSolidColor');
  const uSampler    = gl.getUniformLocation(shaderProgram, 'uSampler');

  // ---------------------------------------------------------
  // 4) Buffers: [pos.x, pos.y, tex.x, tex.y, colorMode]
  // ---------------------------------------------------------
  const buffer = gl.createBuffer();

  function createBufferData(posArray, texArray, colModeArray) {
    const data = [];
    for (let i = 0; i < posArray.length; i += 2) {
      data.push(
        posArray[i], posArray[i + 1],    // position
        texArray[i], texArray[i + 1],    // texCoord
        colModeArray[i / 2]             // colorMode
      );
    }
    return new Float32Array(data);
  }

  let positions    = null;
  let texcoords    = null;
  let colorModeArr = null;

  function setupQuad(aspect) {
    // Fit the sub-frame fully in [-1..+1].
    // If aspect >= 1 => wide => width=2, height=2/aspect
    // If aspect < 1  => tall => height=2, width=2*aspect
    let halfWidth, halfHeight;
    if (aspect >= 1.0) {
      halfWidth  = 1.0;
      halfHeight = 1.0 / aspect;
    } else {
      halfHeight = 1.0;
      halfWidth  = aspect;
    }

    positions = new Float32Array([
      -halfWidth, -halfHeight,
       halfWidth, -halfHeight,
      -halfWidth,  halfHeight,
       halfWidth,  halfHeight
    ]);

    if (mode === 'test') {
      // colorMode=1 => solid color
      texcoords = new Float32Array([0,0, 1,0, 0,1, 1,1]);
      colorModeArr = [1, 1, 1, 1];
    } else {
      // colorMode=0 => texture
      texcoords = new Float32Array([0,0, 1,0, 0,1, 1,1]);
      colorModeArr = [0, 0, 0, 0];
    }

    const data = createBufferData(positions, texcoords, colorModeArr);
    gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
    gl.bufferData(gl.ARRAY_BUFFER, data, gl.STATIC_DRAW);
  }

  // ---------------------------------------------------------
  // 5) Texture loading
  // ---------------------------------------------------------
  let texture    = null;
  let frameCount = 0;
  let subImageIdx= 0;

  const colorCyan = [0, 1, 1, 1];
  const colorRed  = [1, 0, 0, 1];
  let currentColor= colorCyan;

  const textureImages = {
    viking4:  'viking.png',      // 4 frames horizontally
    viking32: 'viking32.png',    // 32 frames => 8×4
    statue32: 'statue32.png'     // 32 frames => 8×4
  };

  if (mode in textureImages) {
    gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);

    texture = gl.createTexture();
    const image = new Image();
    image.src = textureImages[mode];
    image.onload = function() {
      gl.bindTexture(gl.TEXTURE_2D, texture);
      gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA,
                    gl.UNSIGNED_BYTE, image);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);

      let columns = 1, rows = 1;
      if (mode === 'viking4') { columns=4; rows=1; }
      else if (mode === 'viking32' || mode === 'statue32') {
        columns=8; rows=4;
      }

      // sub-frame aspect
      const subAspect = (image.width / columns) / (image.height / rows);
      setupQuad(1.0); // or subAspect if you want to preserve each frame's aspect
      requestAnimationFrame(() => render(columns, rows));
    };
  } else {
    // mode="test"
    setupQuad(1.0);
    requestAnimationFrame(() => render(1,1));
  }

  // ---------------------------------------------------------
  // 6) Render loop
  // ---------------------------------------------------------
  function render(columns, rows) {
    gl.clearColor(0, 0, 0, 1);
    gl.clear(gl.COLOR_BUFFER_BIT);

    if (mode === 'test') {
      // Toggle color
      if (frameCount % framesToSwitch === 0) {
        currentColor = (currentColor === colorCyan) ? colorRed : colorCyan;
      }
      gl.uniform4fv(uSolidColor, currentColor);
    } else {
      // multi-frame textures
      const totalFrames = columns * rows;

      // Switch frame
      if (frameCount % framesToSwitch === 0) {
        if (mode === 'viking32' || mode === 'statue32') {
          // Example: reverse
          subImageIdx = (subImageIdx - skipSprite + totalFrames) % totalFrames;
        } else {
          // forward
          subImageIdx = (subImageIdx + skipSprite) % totalFrames;
        }
      }

      gl.activeTexture(gl.TEXTURE0);
      gl.bindTexture(gl.TEXTURE_2D, texture);
      gl.uniform1i(uSampler, 0);

      // Figure out col/row
      const col = subImageIdx % columns;
      const row = Math.floor(subImageIdx / columns);
      const invertedRow = (rows - 1) - row;

      // UV coords
      const uLeft   = col * (1 / columns);
      const uRight  = uLeft + (1 / columns);
      const vTop    = invertedRow * (1 / rows);
      const vBottom = vTop + (1 / rows);

      // Rebuild buffer data
      const data = [];
      for (let i = 0; i < 4; i++) {
        const px = positions[i*2], py = positions[i*2 + 1];
        const oldU = (i % 2 === 1) ? 1.0 : 0.0;
        const oldV = (i >= 2)      ? 1.0 : 0.0;
        const newU = (oldU > 0.5) ? uRight : uLeft;
        const newV = (oldV > 0.5) ? vBottom: vTop;
        data.push(px, py, newU, newV, 0);
      }
      gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(data), gl.STATIC_DRAW);
    }

    // Use program
    gl.useProgram(shaderProgram);

    // Attributes
    gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
    const stride = 5 * 4; // 5 floats (x,y,u,v,colorMode)
    gl.enableVertexAttribArray(aPosition);
    gl.vertexAttribPointer(aPosition, 2, gl.FLOAT, false, stride, 0);

    gl.enableVertexAttribArray(aTexCoord);
    gl.vertexAttribPointer(aTexCoord, 2, gl.FLOAT, false, stride, 2*4);

    gl.enableVertexAttribArray(aColorMode);
    gl.vertexAttribPointer(aColorMode, 1, gl.FLOAT, false, stride, 4*4);

    gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
    frameCount++;
    requestAnimationFrame(() => render(columns, rows));
  }

  /* ========================================================
   *  CAMERA BRIGHTNESS DETECTION SECTION
   *  ========================================================
   *  1) Ask for camera with environment facing mode and try
   *     to get high frameRate. Not guaranteed on all devices.
   *  2) Draw to 32×32 hidden canvas each frame.
   *  3) Compute average brightness. If above threshold, reset
   *     subImageIdx=0 to sync frames on bright flash.
   */

  async function startCamera() {
    try {
      const constraints = {
        audio: false,
        video: {
          facingMode: 'environment', 
          frameRate: { ideal: 60, max: 60 }, // not guaranteed
          width: { ideal: 640 },
          height:{ ideal: 480 },
        }
      };
      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      const videoEl = document.getElementById('video');
      videoEl.srcObject = stream;
      await videoEl.play();
      requestAnimationFrame(checkBrightness);
    } catch (err) {
      console.error('Camera error:', err);
    }
  }

  function checkBrightness() {
    const videoEl = document.getElementById('video');
    const camCanvas = document.getElementById('camCanvas');
    const ctx = camCanvas.getContext('2d');

    // Draw video frame to small canvas
    ctx.drawImage(videoEl, 0, 0, camCanvas.width, camCanvas.height);

    // Get pixel data and compute average
    const frameData = ctx.getImageData(0, 0, camCanvas.width, camCanvas.height);
    const data = frameData.data;
    let sum = 0;
    for (let i = 0; i < data.length; i += 4) {
      sum += (data[i] + data[i+1] + data[i+2]) / 3;
    }
    const numPixels = data.length / 4;
    const brightness = sum / numPixels;

    // Threshold for "flash"
    const threshold = 200;
    if (brightness > threshold) {
      // Reset subImageIdx
      subImageIdx = 0;
    }

    requestAnimationFrame(checkBrightness);
  }

  // Start camera once page is loaded
  window.addEventListener('load', startCamera);

})();
</script>
</body>
</html>